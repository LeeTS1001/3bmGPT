{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cultural-bibliography",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "improving-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "#from datasets import load_dataset\n",
    "#from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-pioneer",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-covering",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flush-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON file for reading\n",
    "with open('/mnt/prj/AJ/dock_bert/Data/0427_docking_data_all.json', 'r') as f:\n",
    "    # Load the JSON data from the file\n",
    "    docking_data_all = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesser-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0718 = [sentence for sentence in docking_data_all if all(len(word) >= 20 for word in sentence.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sized-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "undefined-alliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 11092443/11092443 [04:13<00:00, 43760.69it/s]\n"
     ]
    }
   ],
   "source": [
    "regex = r\"\\d_\\d_[A-Za-z]:[A-Za-z]_[A-Za-z]_[A-Za-z]-[A-Za-z]_[A-Za-z0-9]{1,3}:[A-Za-z0-9]{1,3}_[A-Za-z0-9]{1,3}_[A-Za-z0-9]{1,3}\"\n",
    "data_0718_re =[]\n",
    "data_0718_err =[]\n",
    "for one_sen in tqdm(data_0718):\n",
    "    word_ftwo = [item for item in one_sen.split() if re.fullmatch(regex, item)]\n",
    "    if len(one_sen.split()) == len(word_ftwo):\n",
    "        data_0718_re.append(one_sen)\n",
    "    else:\n",
    "        data_0718_err.append(one_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "molecular-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data_0718_re[0].split():\n",
    "    if len(item) < 21:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "approved-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 10475194/10475194 [01:03<00:00, 165079.65it/s]\n"
     ]
    }
   ],
   "source": [
    "data_0718_re_2 = []\n",
    "data_0718_re_error2 = []\n",
    "for one_sen in tqdm(data_0718_re):\n",
    "    word_ftwo = [item for item in one_sen.split() if len(item) >= 21]\n",
    "    if len(one_sen.split()) == len(word_ftwo):\n",
    "        data_0718_re_2.append(one_sen)\n",
    "    else:\n",
    "        data_0718_re_error2.append(one_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "photographic-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Use the json.dump() method to write the list into a file\n",
    "with open('data_0718_re_2.json', 'w') as f:\n",
    "    json.dump(data_0718_re_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mediterranean-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_0718_re_2.json', 'r') as f:\n",
    "    data_0718_re_2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consecutive-hunger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10475194"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_0718_re_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-producer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3565368/3565368 [00:12<00:00, 282562.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through the list and replace ':' and '-' with an empty string ''\n",
    "for i in tqdm(range((len(docking_data_30p)))):\n",
    "    docking_data_30p[i] = docking_data_30p[i].replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-ridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3565368/3565368 [00:05<00:00, 643091.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through the list and replace ':' and '-' with an empty string ''\n",
    "for i in tqdm(range((len(docking_data_30p)))):\n",
    "    docking_data_30p[i] = docking_data_30p[i].replace(':', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "boxed-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3565368/3565368 [00:04<00:00, 747542.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through the list and replace ':' and '-' with an empty string ''\n",
    "for i in tqdm(range((len(docking_data_30p)))):\n",
    "    docking_data_30p[i] = docking_data_30p[i].replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "modified-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3565368/3565368 [00:14<00:00, 246998.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3241330"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_all=[]\n",
    "for sentence in tqdm(docking_data_30p):\n",
    "    split_sen = sentence.split(' ')\n",
    "    for word in split_sen:\n",
    "        word_all.append(word)\n",
    "len(set(docking_data_30p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "provincial-rachel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3565368/3565368 [00:15<00:00, 234915.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3241330"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_all=[]\n",
    "for sentence in tqdm(docking_data_30p):\n",
    "    split_sen = sentence.split(' ')\n",
    "    for word in split_sen:\n",
    "        word_all.append(word)\n",
    "len(set(docking_data_30p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "alike-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_all = word_all[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "subtle-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file in write mode\n",
    "with open('/mnt/prj/AJ/dock_bert/Data/docking_data_30p.txt', 'w') as file:\n",
    "    # Iterate over the list and write each string to the file\n",
    "    for string in docking_data_30p:\n",
    "        file.write(string)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "reverse-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Example list of data\n",
    "#data = [\"example_1\", \"example_2\", \"example_3\", \"example_4\", \"example_5\", \"example_6\", \"example_7\", \"example_8\", \"example_9\", \"example_10\"]\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(docking_data_30p)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "num_examples = len(docking_data_30p)\n",
    "num_train = int(num_examples * 0.7)  # 70% for training\n",
    "num_val = int(num_examples * 0.2)  # 20% for validation\n",
    "num_test = num_examples - num_train - num_val  # rest for test\n",
    "\n",
    "train_data = docking_data_30p[:num_train]\n",
    "val_data = docking_data_30p[num_train:num_train+num_val]\n",
    "test_data = docking_data_30p[num_train+num_val:]\n",
    "\n",
    "# Save train, validation, and test sets to text files\n",
    "with open(\"/mnt/prj/AJ/dock_bert/Data/train_word_0502.txt\", \"w\") as f:\n",
    "    for example in train_data:\n",
    "        f.write(example + \"\\n\")\n",
    "\n",
    "with open(\"/mnt/prj/AJ/dock_bert/Data/val_word_0502.txt\", \"w\") as f:\n",
    "    for example in val_data:\n",
    "        f.write(example + \"\\n\")\n",
    "\n",
    "with open(\"/mnt/prj/AJ/dock_bert/Data/test_word_0502.txt\", \"w\") as f:\n",
    "    for example in test_data:\n",
    "        f.write(example + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-determination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-morgan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-platinum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-sentence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0125_hazi",
   "language": "python",
   "name": "0125_hazi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
